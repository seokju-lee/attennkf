<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="description" content="Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation">
  <meta property="og:title" content="AttenNKF Project Page" />
  <meta property="og:description"
    content="Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation" />
  <meta property="og:url" content="https://seokju-lee.github.io/attennkf" />
  <meta property="og:image" content="static/images/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />

  <meta name="twitter:title" content="AttenNKF">
  <meta name="twitter:description" content="Attention-Based Neural-Augmented Kalman Filter">
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <meta name="keywords" content="Legged Robots, State Estimation, Kalman Filter, Attention Mechanism">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Attention-Based Neural-Augmented Kalman Filter for Legged Robot State Estimation</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        packages: ['base']
      },
      svg: { fontCache: 'global' }
    };
  </script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js" async></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Attention-Based Neural-Augmented Kalman Filter for Legged Robot
              State Estimation</h1>
            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://seokju-lee.github.io/" target="_blank">Seokju Lee</a>,</span>
              <span class="author-block">Kyung-Soo Kim</span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">
                <a href="https://msc.kaist.ac.kr/" target="_blank">Mechatronics, Systems and Control Lab</a>,
                <a href="https://www.kaist.ac.kr/en/" target="_blank">Korea Advanced Institute of Science and
                  Technology (KAIST)</a><br>IEEE Robotics and Automation Letters (RA-L)</span>
            </div>

            <div class="column has-text-centered">
              <div class="publication-links">
                <span class="link-block">
                  <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-ieee"></i>
                    </span>
                    <span>IEEE Xplore</span>
                  </a>
                </span>

                </span>

                </span>

                <span class="link-block">
                  <a href="" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>


  <section class="hero is-small">
    <div class="hero-body">
      <div class="container">
        <div class="columns is-centered has-text-centered">
          <div class="column is-four-fifths">
            <div class="publication-video">
              <iframe src="https://www.youtube.com/embed/2XHHigqnQgs" frameborder="0" allow="autoplay; encrypted-media"
                allowfullscreen></iframe>
            </div>
            <h2 class="subtitle has-text-centered">
              Supplementary Video of the Paper
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              In this letter, we propose an Attention-Based Neural-Augmented Kalman Filter (AttenNKF) for state
              estimation in legged robots. Foot slip is a major source of estimation error: when slip occurs, kinematic
              measurements violate the no-slip assumption and inject bias during the update step. Our objective is to
              estimate this slip-induced error and compensate for it. To this end, we augment an Invariant Extended
              Kalman Filter (InEKF) with a neural compensator that uses an attention mechanism to infer error
              conditioned on foot-slip severity and then applies this estimate as a post-update compensation to the
              InEKF state (i.e., after the filter update). The compensator is trained in a latent space, which aims to
              reduce sensitivity to raw input scales and encourages structured slip-conditioned compensations, while
              preserving the InEKF recursion. Experiments demonstrate improved performance compared to existing
              legged-robot state estimators, particularly under slip-prone conditions.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Method: Slip as Context</h2>

      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h3 class="title is-4">Overall Architecture</h3>
          <figure class="image">
            <img src="static/images/figure3.jpg" alt="AttenNKF Architecture"
              style="max-width: 40%; height: auto; display: block; margin: 0 auto;">
            <figcaption class="content has-text-justified is-size-6 mt-3" style="max-width: 80%; margin: 0 auto;">
              <strong>Figure 1. Structure of the AttenNKF.</strong> The system augments a standard InEKF with a Neural
              Compensator (NC). Unlike traditional methods that simply concatenate inputs, our NC uses an
              <strong>Attention
                Mechanism</strong> where the <em>Foot Slip Level</em> acts as a context (Query) to modulate the
              <em>InEKF State History</em> (Key/Value).
            </figcaption>
          </figure>
        </div>
      </div>

      <br><br>

      <div class="columns is-centered has-text-centered">
        <div class="column is-full">
          <h3 class="title is-4">Training Process</h3>
          <figure class="image">
            <img src="static/images/figure2.jpg" alt="Training Process"
              style="max-width: 80%; height: auto; display: block; margin: 0 auto;">
            <figcaption class="content has-text-justified is-size-6 mt-3" style="max-width: 100%; margin: 0 auto;">
              <strong>Figure 2. Training pipeline of the Neural Compensator.</strong> The training consists of two
              stages:
              <br>
              <ul style="text-align: left; display: inline-block; text-align: left;">
                <li><strong>Step 1 (Autoencoder):</strong> Compresses the Foot Slip Level, InEKF State, and Error into
                  latent spaces using GRU-based autoencoders.</li>
                <li><strong>Step 2 (Attention):</strong> Trains the Cross-Attention module. The <em>Slip Latent</em> is
                  used as the Query, while the <em>InEKF Latent</em> provides Keys and Values. This generates a
                  slip-conditioned compensation latent vector.</li>
              </ul>
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Experimental Setup</h2>
      <div class="columns is-centered">
        <div class="column is-four-fifths">
          <figure class="image">
            <img src="static/images/figure4.jpg" alt="Experimental Environment"
              style="max-width: 60%; height: auto; display: block; margin: 0 auto;">
            <figcaption class="has-text-justified is-size-6 mt-3" style="max-width: 70%; margin: 0 auto;">
              <strong>Figure 3. Real-world indoor experimental environment.</strong>
              The setup includes: (1) a <strong>Gravel field</strong> (30mm pebbles) to induce noise, (2) a
              <strong>Teflon sheet</strong> ($\mu \approx 0.15$) to simulate ice-like slippery surfaces, and (3)
              <strong>Stairs</strong> for dynamic locomotion tests.
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
  </section>

  <section class="section">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Experimental Environments & Trajectory</h2>
      <div class="content has-text-centered mb-5">
        <p>
          We evaluated the proposed method across various terrain conditions.
          <br>The experiments cover nominal walking, slippery/noisy surfaces, and long-term trajectory tracking.
        </p>
      </div>

      <div class="columns is-centered">
        <div class="column is-4 has-text-centered">
          <h4 class="title is-5">Full Trajectory</h4>
          <video poster="" autoplay controls muted loop playsinline width="100%">
            <source src="static/videos/full_trajectory.mp4" type="video/mp4">
          </video>
          <p class="is-size-7 mt-1">Indoor trajectory</p>
        </div>
        <div class="column is-4 has-text-centered">
          <h4 class="title is-5">Flat Ground</h4>
          <video poster="" autoplay controls muted loop playsinline width="100%">
            <source src="static/videos/flat.mp4" type="video/mp4">
          </video>
          <p class="is-size-7 mt-1">Nominal walking</p>
        </div>
        <div class="column is-4 has-text-centered">
          <h4 class="title is-5">Gravel Field</h4>
          <video poster="" autoplay controls muted loop playsinline width="100%">
            <source src="static/videos/gravel.mp4" type="video/mp4">
          </video>
          <p class="is-size-7 mt-1">Noisy surface (30mm pebbles)</p>
        </div>
      </div>

      <div class="columns is-centered mt-4">
        <div class="column is-4 has-text-centered">
          <h4 class="title is-5">Teflon Sheet</h4>
          <video poster="" autoplay controls muted loop playsinline width="100%">
            <source src="static/videos/teflon.mp4" type="video/mp4">
          </video>
          <p class="is-size-7 mt-1">Slippery surface ($\mu \approx 0.15$)</p>
        </div>
        <div class="column is-4 has-text-centered">
          <h4 class="title is-5">Stairs</h4>
          <video poster="" autoplay controls muted loop playsinline width="100%">
            <source src="static/videos/stairs.mp4" type="video/mp4">
          </video>
          <p class="is-size-7 mt-1">Uneven terrain</p>
        </div>
        <div class="column is-4 has-text-centered">
          <h4 class="title is-5">Soft Terrain</h4>
          <video poster="" autoplay controls muted loop playsinline width="100%">
            <source src="static/videos/ood_soft.mp4" type="video/mp4">
          </video>
          <p class="is-size-7 mt-1">Deformable surface (OOD)</p>
        </div>
      </div>

      <br><br>

      <h3 class="title is-4 has-text-centered">Quantitative Results</h3>

      <div class="columns is-centered is-vcentered">

        <div class="column is-8 has-text-centered">
          <figure class="image">
            <img src="static/images/figure5.jpg" alt="Indoor Experimental Results" style="width: 100%; height: auto;">
          </figure>
        </div>

        <div class="column is-4 has-text-centered">
          <figure class="image">
            <img src="static/images/table_results.png" alt="RMSE Comparison Table" style="width: 100%; height: auto;">
          </figure>
        </div>

      </div>

      <div class="columns is-centered">
        <div class="column is-full">
          <figcaption class="content has-text-justified is-size-6 mt-1" style="max-width: 90%; margin: 0 auto;">
            <strong>Figure 4 & Table 1. State estimation performance.</strong>
            (Left) Trajectories and state histories comparing AttenNKF with baselines.
            (Right) RMSE comparison table showing that AttenNKF achieves the lowest drift, particularly in slippery and
            noisy conditions.
          </figcaption>
        </div>
      </div>

    </div>
  </section>

  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered">Outdoor Experiment</h2>

      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <video poster="" autoplay controls muted loop playsinline width="100%"
            style="border-radius: 10px; box-shadow: 0 0 10px rgba(0,0,0,0.1);">
            <source src="static/videos/outdoor_final.mp4" type="video/mp4">
          </video>
          <p class="content has-text-centered mt-3">
            The robot traversed approximately <strong>100m</strong> on deformable grass terrain.
            While baselines accumulated up to 10m of vertical drift, <strong>AttenNKF</strong> maintained errors within
            $\pm 2-3$m.
          </p>
        </div>
      </div>

      <div class="columns is-centered">
        <div class="column is-full">
          <figure class="image mt-4">
            <img src="static/images/figure6.jpg" alt="Outdoor Experimental Results"
              style="max-width: 60%; height: auto; display: block; margin: 0 auto;">
            <figcaption class="content has-text-justified is-size-6 mt-3" style="max-width: 80%; margin: 0 auto;">
              <strong>Figure 5. Outdoor experiment results.</strong>
              <strong>Top:</strong> Trajectory overlaid on a satellite map.
              <strong>Bottom:</strong> Estimated vertical position ($z$) over time.
            </figcaption>
          </figure>
        </div>
      </div>
    </div>
  </section>

  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>Coming Soon</code></pre>
    </div>
  </section>
  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>
          </div>
        </div>
      </div>
    </div>
  </footer>

</body>

</html>